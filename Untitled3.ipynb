{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b8312e5-dfcd-4078-a5ad-426e0c87dddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution: (array([0, 1, 2]), array([738, 290, 311]))\n",
      "Validation distribution: (array([0, 1, 2]), array([158,  62,  67]))\n",
      "Test distribution: (array([0, 1, 2]), array([158,  62,  67]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m771\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,378,278</span> (16.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,378,278\u001b[0m (16.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,707</span> (1.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m328,707\u001b[0m (1.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442ms/step - accuracy: 0.4971 - loss: 1.0394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 609ms/step - accuracy: 0.4980 - loss: 1.0389 - val_accuracy: 0.5505 - val_loss: 1.0013\n",
      "Epoch 2/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 482ms/step - accuracy: 0.5678 - loss: 0.9943 - val_accuracy: 0.5505 - val_loss: 1.0016\n",
      "Epoch 3/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 540ms/step - accuracy: 0.5542 - loss: 1.0020 - val_accuracy: 0.5505 - val_loss: 0.9998\n",
      "Epoch 4/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 546ms/step - accuracy: 0.5435 - loss: 1.0214 - val_accuracy: 0.5505 - val_loss: 0.9994\n",
      "Epoch 5/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 608ms/step - accuracy: 0.5526 - loss: 1.0027 - val_accuracy: 0.5505 - val_loss: 0.9987\n",
      "Epoch 6/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 532ms/step - accuracy: 0.5174 - loss: 1.0356 - val_accuracy: 0.5505 - val_loss: 1.0014\n",
      "Epoch 7/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 524ms/step - accuracy: 0.5593 - loss: 1.0015 - val_accuracy: 0.5505 - val_loss: 1.0022\n",
      "Epoch 8/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 550ms/step - accuracy: 0.5518 - loss: 1.0079 - val_accuracy: 0.5505 - val_loss: 1.0021\n",
      "Epoch 9/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 530ms/step - accuracy: 0.5781 - loss: 0.9888 - val_accuracy: 0.5505 - val_loss: 1.0008\n",
      "Epoch 10/30\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 525ms/step - accuracy: 0.5532 - loss: 1.0012 - val_accuracy: 0.5505 - val_loss: 0.9999\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 497ms/step - accuracy: 0.5375 - loss: 1.0123\n",
      "Test Accuracy: 55.05%\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/Subhankar/Ml/Model For Cow /Model/path_to_your_image.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 134\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m    133\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_your_image.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 134\u001b[0m result \u001b[38;5;241m=\u001b[39m predict_lumpy(image_path)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[0;32mIn[14], line 111\u001b[0m, in \u001b[0;36mpredict_lumpy\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_lumpy\u001b[39m(image_path):\n\u001b[0;32m--> 111\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    112\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))\n\u001b[1;32m    113\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/PIL/Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[1;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/Subhankar/Ml/Model For Cow /Model/path_to_your_image.jpg'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_images(directory, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize((224, 224))  # Resize for EfficientNet\n",
    "            img = np.array(img) / 255.0   # Normalize pixel values [0,1]\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load datasets\n",
    "non_lumpy_dir = \"Lumpy Dataset/NonLumpyCows/ClearImages\"\n",
    "stage1_dir = \"Lumpy Dataset/LumpyCows/STAGE1/clear visible\"\n",
    "severe_dir = \"Lumpy Dataset/LumpyCows/SEVER\"\n",
    "\n",
    "X_non_lumpy, y_non_lumpy = load_images(non_lumpy_dir, 0)\n",
    "X_stage1, y_stage1 = load_images(stage1_dir, 1)\n",
    "X_severe, y_severe = load_images(severe_dir, 2)\n",
    "\n",
    "# Combine datasets\n",
    "X = np.concatenate([X_non_lumpy, X_stage1, X_severe])\n",
    "y = np.concatenate([y_non_lumpy, y_stage1, y_severe])\n",
    "\n",
    "# Split datasets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "print(\"Train distribution:\", np.unique(y_train, return_counts=True))\n",
    "print(\"Validation distribution:\", np.unique(y_val, return_counts=True))\n",
    "print(\"Test distribution:\", np.unique(y_test, return_counts=True))\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Model building\n",
    "def build_model():\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False  # Freeze layers initially\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(3, activation='softmax')(x)  # 3 classes: 0=NonLumpy, 1=STAGE1, 2=SEVERE\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Prediction function\n",
    "def predict_lumpy(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    \n",
    "    pred = model.predict(img_array)\n",
    "    class_idx = np.argmax(pred)\n",
    "    confidence = np.max(pred)\n",
    "    \n",
    "    classes = {0: \"Non-Lumpy (Healthy)\", 1: \"STAGE1 (Early Lumpy)\", 2: \"SEVERE (Advanced Lumpy)\"}\n",
    "    \n",
    "    return {\n",
    "        \"prediction\": classes[class_idx],\n",
    "        \"confidence\": float(confidence),\n",
    "        \"class_probabilities\": {\n",
    "            \"Non-Lumpy\": float(pred[0][0]),\n",
    "            \"STAGE1\": float(pred[0][1]),\n",
    "            \"SEVERE\": float(pred[0][2])\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "image_path = \"path_to_your_image.jpg\"\n",
    "result = predict_lumpy(image_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7be7d5b-0e34-477d-a4eb-696b0e4d7e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded samples: (1913, 224, 224, 3) (1913,)\n",
      "\n",
      "🔁 Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 248ms/step - accuracy: 0.4696 - loss: 0.1243 - val_accuracy: 0.5326 - val_loss: 0.1175 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 215ms/step - accuracy: 0.5452 - loss: 0.1164 - val_accuracy: 0.5561 - val_loss: 0.1128 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.5413 - loss: 0.1146 - val_accuracy: 0.5379 - val_loss: 0.1134 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - accuracy: 0.5666 - loss: 0.1130 - val_accuracy: 0.5509 - val_loss: 0.1111 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 215ms/step - accuracy: 0.5490 - loss: 0.1137 - val_accuracy: 0.5509 - val_loss: 0.1082 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 209ms/step - accuracy: 0.5546 - loss: 0.1115 - val_accuracy: 0.5509 - val_loss: 0.1121 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - accuracy: 0.5606 - loss: 0.1115 - val_accuracy: 0.5509 - val_loss: 0.1198 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 232ms/step - accuracy: 0.5476 - loss: 0.1119 - val_accuracy: 0.5509 - val_loss: 0.1148 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - accuracy: 0.5404 - loss: 0.1137 - val_accuracy: 0.5509 - val_loss: 0.1253 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.5547 - loss: 0.1122\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - accuracy: 0.5547 - loss: 0.1122 - val_accuracy: 0.4569 - val_loss: 0.1481 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 218ms/step - accuracy: 0.5316 - loss: 0.1151 - val_accuracy: 0.5483 - val_loss: 0.1402 - learning_rate: 5.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - accuracy: 0.5629 - loss: 0.1114 - val_accuracy: 0.2324 - val_loss: 0.1712 - learning_rate: 5.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - accuracy: 0.5458 - loss: 0.1113 - val_accuracy: 0.2115 - val_loss: 0.2224 - learning_rate: 5.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 238ms/step - accuracy: 0.5546 - loss: 0.1133 - val_accuracy: 0.2533 - val_loss: 0.1994 - learning_rate: 5.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.5507 - loss: 0.1122\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.5509 - loss: 0.1122 - val_accuracy: 0.3864 - val_loss: 0.1953 - learning_rate: 5.0000e-05\n",
      "Epoch 1/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 236ms/step - accuracy: 0.3886 - loss: 0.1614 - val_accuracy: 0.5509 - val_loss: 0.2781\n",
      "Epoch 2/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 233ms/step - accuracy: 0.4868 - loss: 0.1465 - val_accuracy: 0.5509 - val_loss: 0.5010\n",
      "Epoch 3/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 231ms/step - accuracy: 0.5181 - loss: 0.1397 - val_accuracy: 0.5509 - val_loss: 0.7336\n",
      "Epoch 4/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - accuracy: 0.5189 - loss: 0.1410 - val_accuracy: 0.5509 - val_loss: 0.9608\n",
      "Epoch 5/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 234ms/step - accuracy: 0.5329 - loss: 0.1313 - val_accuracy: 0.5509 - val_loss: 1.2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[211   0   0]\n",
      " [ 83   0   0]\n",
      " [ 89   0   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.55      1.00      0.71       211\n",
      "      Stage1       0.00      0.00      0.00        83\n",
      "      Severe       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.55       383\n",
      "   macro avg       0.18      0.33      0.24       383\n",
      "weighted avg       0.30      0.55      0.39       383\n",
      "\n",
      "\n",
      "🔁 Fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 267ms/step - accuracy: 0.4485 - loss: 0.1220 - val_accuracy: 0.2167 - val_loss: 0.1495 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.5539 - loss: 0.1167 - val_accuracy: 0.3211 - val_loss: 0.1218 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - accuracy: 0.5553 - loss: 0.1141 - val_accuracy: 0.5509 - val_loss: 0.1155 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 217ms/step - accuracy: 0.5159 - loss: 0.1148 - val_accuracy: 0.5509 - val_loss: 0.1111 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 216ms/step - accuracy: 0.5514 - loss: 0.1133 - val_accuracy: 0.5509 - val_loss: 0.1119 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 237ms/step - accuracy: 0.5673 - loss: 0.1131 - val_accuracy: 0.5039 - val_loss: 0.1123 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 225ms/step - accuracy: 0.5510 - loss: 0.1124 - val_accuracy: 0.5509 - val_loss: 0.1117 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 226ms/step - accuracy: 0.5530 - loss: 0.1117 - val_accuracy: 0.5483 - val_loss: 0.1131 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - accuracy: 0.5510 - loss: 0.1134 - val_accuracy: 0.5849 - val_loss: 0.1075 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 217ms/step - accuracy: 0.5409 - loss: 0.1122 - val_accuracy: 0.5509 - val_loss: 0.1289 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 219ms/step - accuracy: 0.5354 - loss: 0.1117 - val_accuracy: 0.5509 - val_loss: 0.1446 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - accuracy: 0.5722 - loss: 0.1103 - val_accuracy: 0.5483 - val_loss: 0.2116 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 225ms/step - accuracy: 0.5585 - loss: 0.1110 - val_accuracy: 0.3238 - val_loss: 0.2117 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.5452 - loss: 0.1122\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - accuracy: 0.5455 - loss: 0.1122 - val_accuracy: 0.5196 - val_loss: 0.2028 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - accuracy: 0.5681 - loss: 0.1103 - val_accuracy: 0.5535 - val_loss: 0.1999 - learning_rate: 5.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 223ms/step - accuracy: 0.5683 - loss: 0.1099 - val_accuracy: 0.5196 - val_loss: 0.1732 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 244ms/step - accuracy: 0.5744 - loss: 0.1110 - val_accuracy: 0.5326 - val_loss: 0.1706 - learning_rate: 5.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - accuracy: 0.5516 - loss: 0.1117 - val_accuracy: 0.5587 - val_loss: 0.1446 - learning_rate: 5.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.5551 - loss: 0.1114\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - accuracy: 0.5552 - loss: 0.1114 - val_accuracy: 0.5352 - val_loss: 0.1396 - learning_rate: 5.0000e-05\n",
      "Epoch 1/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 242ms/step - accuracy: 0.5397 - loss: 0.1416 - val_accuracy: 0.5509 - val_loss: 0.7411\n",
      "Epoch 2/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 234ms/step - accuracy: 0.5559 - loss: 0.1325 - val_accuracy: 0.5509 - val_loss: 1.3996\n",
      "Epoch 3/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 265ms/step - accuracy: 0.5355 - loss: 0.1306 - val_accuracy: 0.5509 - val_loss: 1.7077\n",
      "Epoch 4/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 253ms/step - accuracy: 0.5597 - loss: 0.1375 - val_accuracy: 0.5509 - val_loss: 1.8722\n",
      "Epoch 5/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 246ms/step - accuracy: 0.5355 - loss: 0.1300 - val_accuracy: 0.5509 - val_loss: 1.8961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[211   0   0]\n",
      " [ 83   0   0]\n",
      " [ 89   0   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.55      1.00      0.71       211\n",
      "      Stage1       0.00      0.00      0.00        83\n",
      "      Severe       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.55       383\n",
      "   macro avg       0.18      0.33      0.24       383\n",
      "weighted avg       0.30      0.55      0.39       383\n",
      "\n",
      "\n",
      "🔁 Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 241ms/step - accuracy: 0.3931 - loss: 0.1229 - val_accuracy: 0.2324 - val_loss: 0.1495 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 214ms/step - accuracy: 0.5630 - loss: 0.1156 - val_accuracy: 0.2324 - val_loss: 0.1245 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - accuracy: 0.5482 - loss: 0.1140 - val_accuracy: 0.5614 - val_loss: 0.1154 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - accuracy: 0.5500 - loss: 0.1138 - val_accuracy: 0.5457 - val_loss: 0.1121 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - accuracy: 0.5406 - loss: 0.1134 - val_accuracy: 0.3812 - val_loss: 0.1203 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - accuracy: 0.5584 - loss: 0.1137 - val_accuracy: 0.2193 - val_loss: 0.1302 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 221ms/step - accuracy: 0.5540 - loss: 0.1124 - val_accuracy: 0.4491 - val_loss: 0.1170 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - accuracy: 0.5600 - loss: 0.1116 - val_accuracy: 0.5509 - val_loss: 0.1403 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.5688 - loss: 0.1104\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 231ms/step - accuracy: 0.5687 - loss: 0.1105 - val_accuracy: 0.5535 - val_loss: 0.1448 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 267ms/step - accuracy: 0.5650 - loss: 0.1113 - val_accuracy: 0.5509 - val_loss: 0.1548 - learning_rate: 5.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 226ms/step - accuracy: 0.5468 - loss: 0.1120 - val_accuracy: 0.5509 - val_loss: 0.1458 - learning_rate: 5.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 231ms/step - accuracy: 0.5799 - loss: 0.1100 - val_accuracy: 0.5509 - val_loss: 0.1369 - learning_rate: 5.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 226ms/step - accuracy: 0.5686 - loss: 0.1101 - val_accuracy: 0.5509 - val_loss: 0.1661 - learning_rate: 5.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.5724 - loss: 0.1106\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 222ms/step - accuracy: 0.5722 - loss: 0.1106 - val_accuracy: 0.5509 - val_loss: 0.1966 - learning_rate: 5.0000e-05\n",
      "Epoch 1/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 272ms/step - accuracy: 0.5369 - loss: 0.1498 - val_accuracy: 0.5535 - val_loss: 0.1204\n",
      "Epoch 2/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 242ms/step - accuracy: 0.5161 - loss: 0.1355 - val_accuracy: 0.5692 - val_loss: 0.1403\n",
      "Epoch 3/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 238ms/step - accuracy: 0.5303 - loss: 0.1347 - val_accuracy: 0.5640 - val_loss: 0.1655\n",
      "Epoch 4/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 236ms/step - accuracy: 0.5148 - loss: 0.1374 - val_accuracy: 0.5614 - val_loss: 0.1989\n",
      "Epoch 5/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 247ms/step - accuracy: 0.5210 - loss: 0.1325 - val_accuracy: 0.5509 - val_loss: 0.2516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[211   0   0]\n",
      " [ 83   0   0]\n",
      " [ 89   0   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.55      1.00      0.71       211\n",
      "      Stage1       0.00      0.00      0.00        83\n",
      "      Severe       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.55       383\n",
      "   macro avg       0.18      0.33      0.24       383\n",
      "weighted avg       0.30      0.55      0.39       383\n",
      "\n",
      "\n",
      "🔁 Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 244ms/step - accuracy: 0.4573 - loss: 0.1209 - val_accuracy: 0.5524 - val_loss: 0.1125 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 239ms/step - accuracy: 0.5613 - loss: 0.1152 - val_accuracy: 0.5524 - val_loss: 0.1117 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 216ms/step - accuracy: 0.5452 - loss: 0.1161 - val_accuracy: 0.5524 - val_loss: 0.1161 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 224ms/step - accuracy: 0.5476 - loss: 0.1137 - val_accuracy: 0.5524 - val_loss: 0.1135 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 223ms/step - accuracy: 0.5686 - loss: 0.1105 - val_accuracy: 0.5524 - val_loss: 0.1109 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 223ms/step - accuracy: 0.5543 - loss: 0.1118 - val_accuracy: 0.5524 - val_loss: 0.1143 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - accuracy: 0.5473 - loss: 0.1127 - val_accuracy: 0.5524 - val_loss: 0.1171 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 263ms/step - accuracy: 0.5517 - loss: 0.1135 - val_accuracy: 0.2199 - val_loss: 0.1349 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 225ms/step - accuracy: 0.5595 - loss: 0.1131 - val_accuracy: 0.2304 - val_loss: 0.1285 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.5659 - loss: 0.1107\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 228ms/step - accuracy: 0.5657 - loss: 0.1107 - val_accuracy: 0.5524 - val_loss: 0.1321 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 233ms/step - accuracy: 0.5634 - loss: 0.1106 - val_accuracy: 0.5524 - val_loss: 0.1165 - learning_rate: 5.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m617s\u001b[0m 13s/step - accuracy: 0.5566 - loss: 0.1127 - val_accuracy: 0.5524 - val_loss: 0.1263 - learning_rate: 5.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 236ms/step - accuracy: 0.5633 - loss: 0.1110 - val_accuracy: 0.5550 - val_loss: 0.1357 - learning_rate: 5.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - accuracy: 0.5601 - loss: 0.1115 - val_accuracy: 0.5524 - val_loss: 0.1632 - learning_rate: 5.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.5412 - loss: 0.1122 \n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 13s/step - accuracy: 0.5416 - loss: 0.1122 - val_accuracy: 0.5524 - val_loss: 0.1664 - learning_rate: 5.0000e-05\n",
      "Epoch 1/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - accuracy: 0.5180 - loss: 0.1381 - val_accuracy: 0.5524 - val_loss: 0.4423\n",
      "Epoch 2/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 13s/step - accuracy: 0.5488 - loss: 0.1370 - val_accuracy: 0.5524 - val_loss: 0.8175\n",
      "Epoch 3/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 233ms/step - accuracy: 0.5529 - loss: 0.1310 - val_accuracy: 0.5524 - val_loss: 1.1886\n",
      "Epoch 4/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 213ms/step - accuracy: 0.5038 - loss: 0.1305 - val_accuracy: 0.5524 - val_loss: 1.5138\n",
      "Epoch 5/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 9s/step - accuracy: 0.5506 - loss: 0.1243 - val_accuracy: 0.5524 - val_loss: 1.6392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[211   0   0]\n",
      " [ 82   0   0]\n",
      " [ 89   0   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.55      1.00      0.71       211\n",
      "      Stage1       0.00      0.00      0.00        82\n",
      "      Severe       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.55       382\n",
      "   macro avg       0.18      0.33      0.24       382\n",
      "weighted avg       0.31      0.55      0.39       382\n",
      "\n",
      "\n",
      "🔁 Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 259ms/step - accuracy: 0.5047 - loss: 0.1219 - val_accuracy: 0.2173 - val_loss: 0.1236 - learning_rate: 1.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 211ms/step - accuracy: 0.5568 - loss: 0.1163 - val_accuracy: 0.4005 - val_loss: 0.1193 - learning_rate: 1.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m612s\u001b[0m 13s/step - accuracy: 0.5549 - loss: 0.1152 - val_accuracy: 0.5183 - val_loss: 0.1154 - learning_rate: 1.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - accuracy: 0.5360 - loss: 0.1158 - val_accuracy: 0.5183 - val_loss: 0.1132 - learning_rate: 1.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 13s/step - accuracy: 0.5375 - loss: 0.1141 - val_accuracy: 0.4503 - val_loss: 0.1159 - learning_rate: 1.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 215ms/step - accuracy: 0.5601 - loss: 0.1118 - val_accuracy: 0.5445 - val_loss: 0.1141 - learning_rate: 1.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 206ms/step - accuracy: 0.5600 - loss: 0.1124 - val_accuracy: 0.5497 - val_loss: 0.1168 - learning_rate: 1.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 13s/step - accuracy: 0.5510 - loss: 0.1111 - val_accuracy: 0.5497 - val_loss: 0.1235 - learning_rate: 1.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - accuracy: 0.5449 - loss: 0.1117 - val_accuracy: 0.5445 - val_loss: 0.1104 - learning_rate: 1.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m612s\u001b[0m 13s/step - accuracy: 0.5693 - loss: 0.1105 - val_accuracy: 0.5497 - val_loss: 0.1370 - learning_rate: 1.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - accuracy: 0.5483 - loss: 0.1125 - val_accuracy: 0.5497 - val_loss: 0.2331 - learning_rate: 1.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - accuracy: 0.5361 - loss: 0.1130 - val_accuracy: 0.5497 - val_loss: 0.1381 - learning_rate: 1.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 13s/step - accuracy: 0.5799 - loss: 0.1105 - val_accuracy: 0.3403 - val_loss: 0.1242 - learning_rate: 1.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.5603 - loss: 0.1105\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - accuracy: 0.5603 - loss: 0.1105 - val_accuracy: 0.2199 - val_loss: 0.1713 - learning_rate: 1.0000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 2s/step - accuracy: 0.5609 - loss: 0.1107 - val_accuracy: 0.5785 - val_loss: 0.1198 - learning_rate: 5.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 13s/step - accuracy: 0.5550 - loss: 0.1108 - val_accuracy: 0.2173 - val_loss: 0.1714 - learning_rate: 5.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - accuracy: 0.5745 - loss: 0.1103 - val_accuracy: 0.2199 - val_loss: 0.2416 - learning_rate: 5.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - accuracy: 0.5371 - loss: 0.1123 - val_accuracy: 0.3272 - val_loss: 0.1556 - learning_rate: 5.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - accuracy: 0.5608 - loss: 0.1135 \n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 13s/step - accuracy: 0.5609 - loss: 0.1134 - val_accuracy: 0.5026 - val_loss: 0.1643 - learning_rate: 5.0000e-05\n",
      "Epoch 1/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 220ms/step - accuracy: 0.5441 - loss: 0.1429 - val_accuracy: 0.5497 - val_loss: 0.8453\n",
      "Epoch 2/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m616s\u001b[0m 13s/step - accuracy: 0.5307 - loss: 0.1369 - val_accuracy: 0.5497 - val_loss: 1.6056\n",
      "Epoch 3/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 250ms/step - accuracy: 0.5451 - loss: 0.1332 - val_accuracy: 0.5497 - val_loss: 1.9008\n",
      "Epoch 4/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 13s/step - accuracy: 0.5248 - loss: 0.1319 - val_accuracy: 0.5497 - val_loss: 1.9015\n",
      "Epoch 5/5\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 227ms/step - accuracy: 0.5482 - loss: 0.1373 - val_accuracy: 0.5497 - val_loss: 1.9015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[210   0   0]\n",
      " [ 83   0   0]\n",
      " [ 89   0   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.55      1.00      0.71       210\n",
      "      Stage1       0.00      0.00      0.00        83\n",
      "      Severe       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.55       382\n",
      "   macro avg       0.18      0.33      0.24       382\n",
      "weighted avg       0.30      0.55      0.39       382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, ReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from PIL import Image\n",
    "\n",
    "# ======= EBM-A Supported Loss: Focal Loss with Label Smoothing =======\n",
    "def focal_loss(gamma=2., alpha=0.25, label_smoothing=0.1):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = y_true * (1. - label_smoothing) + label_smoothing / tf.cast(tf.shape(y_true)[-1], tf.float32)\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = alpha * tf.math.pow(1 - y_pred, gamma)\n",
    "        return tf.reduce_sum(weight * cross_entropy, axis=1)\n",
    "    return loss\n",
    "\n",
    "# ======= Load and preprocess all images into arrays =======\n",
    "def load_images_from_dirs(dirs, labels_map, img_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label_name, folder in dirs.items():\n",
    "        label = labels_map[label_name]\n",
    "        for fname in os.listdir(folder):\n",
    "            if not fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                continue\n",
    "            path = os.path.join(folder, fname)\n",
    "            try:\n",
    "                img = Image.open(path).convert('RGB').resize(img_size)\n",
    "                images.append(np.array(img) / 255.0)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load {path}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "base_path = \"Lumpy Dataset\"\n",
    "dirs = {\n",
    "    \"Normal\": os.path.join(base_path, \"NonLumpyCows\", \"ClearImages\"),\n",
    "    \"Stage1\": os.path.join(base_path, \"LumpyCows\", \"STAGE1\", \"clear visible\"),\n",
    "    \"Severe\": os.path.join(base_path, \"LumpyCows\", \"SEVER\")\n",
    "}\n",
    "labels_map = {\"Normal\": 0, \"Stage1\": 1, \"Severe\": 2}\n",
    "\n",
    "X, y = load_images_from_dirs(dirs, labels_map)\n",
    "print(\"Loaded samples:\", X.shape, y.shape)\n",
    "\n",
    "# ======= 5-Fold Stratified Cross-Validation =======\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "num_classes = 3\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "    print(f\"\\n🔁 Fold {fold}\")\n",
    "\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = to_categorical(y[train_idx], num_classes), to_categorical(y[val_idx], num_classes)\n",
    "\n",
    "    # Augment only training data\n",
    "    train_aug = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    val_aug = ImageDataGenerator()\n",
    "\n",
    "    train_gen = train_aug.flow(X_train, y_train, batch_size=32)\n",
    "    val_gen = val_aug.flow(X_val, y_val, batch_size=32)\n",
    "\n",
    "    # ======= Model Definition =======\n",
    "    base_model = MobileNetV3Small(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "    base_model.trainable = False  # Freeze early on\n",
    "\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-4),\n",
    "                  loss=focal_loss(label_smoothing=0.1),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # ======= Callbacks =======\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss'),\n",
    "        ReduceLROnPlateau(factor=0.5, patience=5, verbose=1)\n",
    "    ]\n",
    "\n",
    "    # ======= Train (Stage 1) =======\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=30, callbacks=callbacks)\n",
    "\n",
    "    # ======= Progressive Unfreezing (Stage 2) =======\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-20]:  # Keep most layers frozen\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.AdamW(1e-5, weight_decay=1e-4),\n",
    "                  loss=focal_loss(label_smoothing=0.1),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=5)\n",
    "\n",
    "    # ======= TTA Evaluation =======\n",
    "    def tta_predict(model, images, steps=5):\n",
    "        preds = []\n",
    "        tta_gen = ImageDataGenerator(\n",
    "            rotation_range=15, horizontal_flip=True, brightness_range=[0.8, 1.2]\n",
    "        )\n",
    "        for _ in range(steps):\n",
    "            aug = tta_gen.flow(images, shuffle=False, batch_size=32)\n",
    "            preds.append(model.predict(aug, verbose=0))\n",
    "        return np.mean(preds, axis=0)\n",
    "\n",
    "    y_pred = np.argmax(tta_predict(model, X_val), axis=1)\n",
    "    y_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_true, y_pred, target_names=labels_map.keys()))\n",
    "\n",
    "    model.save(f\"lumpy_model_fold{fold}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ffa195-da12-40fc-9f1a-af6ddc992efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
